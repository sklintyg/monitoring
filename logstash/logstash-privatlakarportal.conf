### Input sections that can be used for local testing.
## Beats
#input {
#  beats {
#    port => "5044"
#    add_field => { "deployment" => "privatlakarportal" }
#  }
#}
## Read straight from example file (remember to clear sincedb file)
#input {
#  file {
#    path => "<path_to_project>/logstash/logs/privatlakarportal-monitoring.log"
#    mode => "tail"
#    start_position => "beginning"
#    ignore_older => "52 weeks"
#    add_field => { "deployment" => "privatlakarportal" }
#  }
#}
###

filter {
  # Input should add the field "deployment"
  if [deployment] =~ "privatlakarportal" {

    # General parsing of message into elements always present in the log messages.
    grok {
      patterns_dir => "$PATTERNS_DIR"
      match => { "message" => [
        "^%{WEBCERTTIMESTAMP:date}%{SPACE}%{LOGLEVEL:loglevel}%{SPACE}\[%{WORD:logtype},%{SESSION:session},%{TRACE:trace}\]%{SPACE}---%{SPACE}%{NOTSPACE:javaclass}%{SPACE}:%{SPACE}%{GREEDYDATA:msg}",
        # Tomcat/Catalina format
        "^%{WEBCERTTIMESTAMP:date}%{SPACE}\[%{NOTSPACE:javathread}\]%{SPACE}%{LOGLEVEL:loglevel}%{SPACE}%{NOTSPACE:javaclass}-%{SPACE}%{GREEDYDATA:msg}"
      ] }
      tag_on_failure => "otherLogPattern"
    }

    # ISO8601 forces us to parse the date seperately.
    date {
      locale => "en"
      match => ["date", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd HH:mm:ss,SSS"]
      target => "@timestamp"
      tag_on_failure => "_dateparsefailure"
    }

    # Kibana does not handle - very well in filters (as - is used to show null-values)
    if [session] == "-" { mutate { remove_field => ["session"] } }
    if [trace]   == "-" { mutate { remove_field => ["trace"] } }

    # logtype is parsed from the message
    if [logtype] == "monitoring" {
      # General parsing of message into elements always present in monitoring messages.
      grok {
        match          => ["msg", "%{WORD:event}%{SPACE}%{GREEDYDATA:msg}"]
        overwrite      => ["msg"]
        tag_on_failure => "monitoringparsefailure"
      }

      if [event] =~ "USER_(DELETED|DETAILS_CHANGED|REGISTERED)" {
        grok {
          add_tag        => ["USER"]
          overwrite      => ["user"]            # We will replace this with the user id specified in the message
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{PLK__USER_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else if [event] =~ "USER_(LOGIN|LOGOUT)" {
        grok {
          add_tag        => ["AUTH"]
          overwrite      => ["user"]            # We will replace this with the user id specified in the message
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{PLK__AUTH_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else if [event] =~ "(HOSP_(AUTHORIZED|NOT_AUTHORIZED|WAITING)|REGISTRATION_REMOVED)" {
        grok {
          add_tag        => ["HOSP"]
          overwrite      => ["user"]            # We will replace this with the user id specified in the message
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{PLK__HOSP_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else {
        mutate {
          add_tag => ["OTHER"]
        }
      }
    }
  }
}

### Output sections that can be used for testing
#
## Print all log messages
#output { stdout { codec => rubydebug } }
#
## Print all non-parsable log messages
#output { if "_grokparsefailure" in [tags] { stdout { codec => rubydebug } } }
#output { if "monitoringparsefailure" in [tags] { stdout { codec => rubydebug } } }
#output { if "otherLogPattern" in [tags] { stdout { codec => rubydebug } } }
#
## Send ALL output to local elasticsearch (no physical logs anymore)
#output { elasticsearch { hosts => ["localhost"] } }
#
###
