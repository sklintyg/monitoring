### Input section used for local testing.
#
## Beats
#input {
#  beats {
#    port => "5044"
#    add_field => { "deployment" => "statistik" }
#  }
#}
## Read straight from example file (remember to clear sincedb file)
#input {
#  file {
#    path => "<path_to_project>/logstash/logs/statistik-monitoring.log"
#    mode => "tail"
#    start_position => "beginning"
#    ignore_older => "52 weeks"
#    add_field => { "deployment" => "statistik" }
#  }
#}
###

filter {
  if [deployment] =~ "statistik" {
    grok {
      patterns_dir => "$PATTERNS_DIR"
      match => { "message" => [
        "^%{WEBCERTTIMESTAMP:date}%{SPACE}%{LOGLEVEL:loglevel}%{SPACE}\[%{WORD:logtype},%{SESSION:session},%{TRACE:trace}\]%{SPACE}---%{SPACE}%{NOTSPACE:javaclass}%{SPACE}:%{SPACE}%{GREEDYDATA:msg}",
        # Tomcat/Catalina format
        "^%{WEBCERTTIMESTAMP:date}%{SPACE}\[%{NOTSPACE:javathread}\]%{SPACE}%{LOGLEVEL:loglevel}%{SPACE}%{NOTSPACE:javaclass}-%{SPACE}%{GREEDYDATA:msg}"
      ] }
      tag_on_failure => "otherLogPattern"
    }

    # ISO8601 forces us to parse the date seperately.
    date {
      locale => "en"
      match => ["date", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd HH:mm:ss,SSS"]
      target => "@timestamp"
      tag_on_failure => "_dateparsefailure"
    }

    # Kibana does not handle - very well in filters (as - is used to show null-values)
    if [session] == "-" { mutate { remove_field => ["session"] } }
    if [trace]   == "-" { mutate { remove_field => ["trace"] } }

    # logtype is parsed from the message
    if [logtype] == "monitoring" {
      # General parsing of message into elements always present in monitoring messages.
      grok {
        match          => ["msg", "%{WORD:event}%{SPACE}%{GREEDYDATA:msg}"]
        overwrite      => ["msg"]
        tag_on_failure => "monitoringparsefailure"
      }

      if [event] =~ "USER_LOGIN" {
        grok {
          add_tag        => ["AUTH"]
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{ST__AUTH_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else if [event] =~ "FILE_UPLOAD" {
        grok {
          add_tag        => ["FILE"]
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{ST__FILE_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else if [event] =~ "IN_(FROM_QUEUE|FROM_TABLE)" {
        grok {
          add_tag        => ["IN"]
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{ST__IN_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else if [event] =~ "TRACK_(ACCESS_PROTECTED_CHART_DATA|ACCESS_ANONYMOUS_CHART_DATA)" {
        grok {
          add_tag        => ["TRACK"]
          patterns_dir   => "$PATTERNS_DIR"
          match          => ["msg", "%{ST__TRACK_PARSE}"]
          tag_on_failure => "monitoringparsefailure"
        }
      } else {
        mutate {
          add_tag => ["OTHER"]
        }
      }
    }
  }
}

### Output sections that can be used for testing
#
## Print all log messages
#output { stdout { codec => rubydebug } }
#
## Print all non-parsable log messages
#output { if "_grokparsefailure" in [tags] { stdout { codec => rubydebug } } }
#output { if "monitoringparsefailure" in [tags] { stdout { codec => rubydebug } } }
#output { if "otherLogPattern" in [tags] { stdout { codec => rubydebug } } }
#
## Send ALL output to local elasticsearch (no physical logs anymore)
#output { elasticsearch { hosts => ["localhost"] } }
#
#output { if [trace] == "-" { stdout { codec => rubydebug } } }
###
